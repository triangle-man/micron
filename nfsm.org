#+title: Finite state machines
#+startup: showall
#+options: toc:nil
#+latex_header: \newcommand{\sync}{\mathbin{\&}}
#+latex_header: \newcommand{\then}{\mathbin{;}}
#+latex_header: \newcommand{\while}{\mid}
#+latex_header: \newcommand{\e}{\varepsilon}
#+latex_header: \newcommand{\unit}{\mathbf{1}}
#+latex_header: \newcommand{\void}{\mathbf{0}}
#+latex_header: \newcommand{\all}{\mathbf{U}}
#+latex_header: \DeclareMathOperator{\az}{alph}
#+latex_header: \newcommand{\known}{\Omega}


* Behaviors

Fix, once and for all, an infinite set, $\Sigma$, of /symbols/.

A /history/ is a finite sequence, $(\sigma_1, \sigma_2, \dotsc, \sigma_N)$, of
symbols from $\Sigma$. The empty history is written $\e$. The
/concatenation/ of two histories $h$ and $g$, written $hg$, consists of all the
symbols of $h$ followed by all the symbols of $g$. Clearly $\e f = f\e = f$ for
any history $f$. The /alphabet/ of $h$, written $\az(h)$, is the set of all
symbols that occur in $h$.

A /behaviour/, $(B, \mathcal{A})$, is a set, $B$, of histories, together with a
finite set of symbols $\mathcal{A}\subset\Sigma$, called the alphabet of $B$,
such that $\az(h)\subset\mathcal{A}$ for every history $h\in B$. We often write
$B$ for the behaviour where $\mathcal{A}$ is obvious.

Here are three special behaviours: 
1. The behaviour $\void = \emptyset$, consisting of no sequences.
2. The behaviour $\unit = \{\e\}$, consisting only of the empty sequence.
3. The behaviour $\all = \mathcal{A}^\ast$, consisting of all possible finite
   sequences of symbols from some alphabet $\mathcal{A}$.[fn:kleene]

A behaviour consisting of a single history describes a machine whose entire
computation is known. If there are multiple histories then there are, in some
sense, multiple possible paths of computation. Given two behaviours $P$ and $Q$
we say that $P$ is /more specific/ than $Q$ if $P\subset Q$. That is, $P$ is
more specific than $Q$ if every history in $P$ also occurs in $Q$.

Later, we deal with behaviours that represent “the environemnt”, the part of the
world external to the programs we write but which interact with those programs. 

The intended interpretation of all this is that a history is a particular
computation of a state machine. A behaviour is the set of all possible
computations of that machine. 

It may be that some computation is known “only up to a point.” Let $h$ be a
history. A /prefix/ of $h$ is a finite sequence of symbols $p$ such that $h =
ps$ for some history $s$. If $p$ is a prefix of $h$ we write $p \leq h$.

The /length/ of a sequence, $h$, is the number of symbols in the sequence, which
we denote $|h|$.  For example, $|\e| = 0$. Note that $p \leq h$ implies $|p|
\leq |h|$.

For $B$ a behaviour, the /known history/ of $B$ is the longest sequence $p$ such
that $p \leq h$ for all $h \in B$. The known history is unique: if $p$ and $q$
are two known histories, then $p\leq q$ and $q\leq p$ implies that $|p| = |q|$,
so if, say, $p=qs$, we must have $s = \e$. We write $\known(B)$ for the known
history of $B$. 

The situation we wish to understand is this. There is given to us an
increasingly specific sequence of behaviours, $B_1 \supset B_2 \supset B_3
\dotsb$. This sequence is typically the result of “the interaction of the
machine with its environment up to time $t$.” We wish to compute the
corresponding sequence of known histories, $\known(B_1), \known(B_2), \dotsc$,
representing “the computation of the machine up to time $t$.”

The known history is supposed to be “known.” What we mean by this is that a
later evolution of the behaviour should not change the known history. Luckily,
we have the following trivial result: For behaviours $P$ and $Q$,
\begin{equation}
  P \supset Q \Rightarrow \known(P) \leq \known(Q).
\end{equation}
(This follows, because if $\Omega(P)$ is a prefix of every history in $P$, and
$Q$ is a subset of $P$, then $\Omega(P)$ must also be a prefix of every history
in $Q$.) In other words, as long as the sequence of behaviours is increasingly
specific, then known history will not be rewritten.

Now, given the increasing nature of the known history, an /efficient/ machine
should not need to recompute the full history each time a new behaviour is
given. Instead, it should take in the “change in behaviour” and compute the “change
in the known history”.



* Behaviour algebra

Let $M$ and $N$ be behaviours. By 
\begin{equation}
M\then N 
\end{equation}
(pronounced “$M$ then $N$”) we mean the behaviour whose histories consist of all
those that can be obtained as a sequence in $M$ concatenated with a sequence in
$N$. Note that the “semicolon operator” is associative but not commutative.

We have immediately that
\begin{equation}
M\then\unit = \unit\then M = M
\end{equation}
and
\begin{equation}
M\then\void = \void\then M = \void
\end{equation}
for any behaviour $M$, except the special case $\void\then \unit = \unit \then
\void = \void$. 

As a special case, suppose $M$ is a behaviour and $\alpha$ is a symbol. Then 
\begin{equation}
\alpha \to M
\end{equation}
is the behaviour consisting of all histories in $M$, prefixed
with the symbol $\alpha$.

Let $M$ and $N$ be behaviours as above. Then by
\begin{equation}
M \sync N
\end{equation}
we mean the behaviour whose histories are those that occur in both $M$ and
$N$. The operator $\sync$ is associative and---unlike the semicolon
operator---commutative. We also have the identities:
\begin{equation}
M\sync \void = \void\sync M = \void,
\end{equation}
\begin{equation}
M\sync \all = \all\sync M = M,
\end{equation}
(as long as $M\neq \void$), and
\begin{equation}
M \sync M = M.
\end{equation}

The distributive law only “works” in one direction:
\begin{equation}
P\then (M\sync N) \subseteq (P\then M)\sync (P\then N) 
\end{equation}

This way is certainly true, because an element of the lhs is a history in $P$,
say $p$, followed by a history in both $M$ and $N$, say $q$, so the history $pq$
is certainly in both behaviours on the rhs.

Conversely, suppose $P = \{\e, \alpha\}$, $M = \{\alpha, \alpha\beta\}$, and $N
= \{\beta\}$. Then both $P\then M$ and $P\then N$ include the history
$\alpha\beta$ (coming from $\e\,\alpha\beta$ in the one case and $\alpha\,\beta$
in the other). But $M\sync N = \void$, so the lhs is empty. 

Note that insisting that behaviours were prefix-closed would not have helped us
here since the argument goes through with $P = \{\e, \alpha\}$, $M = \{\e, \alpha,
\alpha\beta\}$, and $N = \{\e, \beta\}$. In this case $M\sync N = \{\e\}$, which
still does not include $\alpha\beta$.

Let $M$ and $N$ be behaviours as above. By
\begin{equation}
M\while N
\end{equation}
we mean the behaviour whose histories are the set union of the histories of $M$
and $N$. The operator $\while$ is associative and commutative.

We have the identities
\begin{equation}
M\while \void = \void\while M = M
\end{equation}
and
\begin{equation}
M\while M = M,  
\end{equation}
as well as the laws
\begin{equation}
P \then (M\while N) = (P\then M) \while (P\then N),  
\end{equation}
and
\begin{equation}
P \sync (M\while N) = (P\sync M) \while (P\sync N).  
\end{equation}
To see the first of these laws, note that a history on the lhs is a history in
$P$ followed by a history in either $M$ or $N$, say $m\in M$, wlog; whereas the
rhs is either a history in $P$ followed by one in $M$ or a history in $P$
followed by one in $M$.

Let $P$ be a behaviour and $\alpha$ a symbol. The /derivative/ of $P$ with
respect to $\alpha$, written $\partial_\alpha P$ is the set of all histories
$(\beta_1, \beta_2, \dotsc)$ for which $(\alpha, \beta_1, \beta_2, \dotsc)$ is a
history in $P$. That is, it is all histories beginning with $\alpha$, without
the $\alpha$. 

Given a finite sequence $(\alpha_1, \alpha_2, \dots, \alpha_N)$, the derivative
$\partial_{\alpha_1\dotsb\alpha_N} P$ is defined as
\begin{equation*}
\partial_{\alpha_1\dotsb \alpha_N} P = \partial_{\alpha_N}\dotsb \partial_{\alpha_2}\partial_{\alpha_1} P,
\end{equation*}
where in addition we define $\partial_\e P = P$. Note that $\partial_\alpha \void = \void$ and, for
any $\alpha\neq\e$, $\partial_\alpha\unit = \void$.

If $M$ is a behaviour, a /prefix/ of $M$ is a history $p$ such that there exists
a behaviour $S$ for which
\begin{equation*}
M = \{p\}\then S,
\end{equation*} 
where $\{p\}$ is the behaviour consisting solely of the history $p$. In other
words, every history in $M$ begins with the sequence of symbols in $p$. 

If $p$ and $p'$ are prefixes of $M$, then clearly either they are equal or one
is a prefix of the another (in the sense of sequences). 


* Interpretation

A behaviour is the set of possible interactions of a program. A history is a
particular interaction. When there is only one history possible, that is the
execution path of the program.

* Reduction relations

- Any history is either $\e$, or $\alpha\to h$ for some symbol $\alpha$ and
  history $h$.

\begin{equation*}
(\alpha \to M) \sync (\beta \to N) =
  \begin{cases}
    \alpha \to (M \sync N) & \text{if $\alpha = \beta$,} \\
    \void & \text{otherwise.}
  \end{cases}
\end{equation*}

- A behaviour consisting of a single history is called /linear:/ it represents a
  deterministic program that just emits the symbols in that history.

- Sometimes a behaviour is “linear up to a point”. The /longest common prefix/
  of a behaviour is the longest history $h$ for which $h$ is a prefix of that
  behaviour.





* Temporal structure and causality

Is there such a thing as non-deterministic behaviour? That would look like a
machine that chose one path only to later find that it “ought” to have taken the
other path. For example, if the environment offered two choices, and the machine
took one of these, leading to a block later. However, here, we “ask the machine
to take both options” so there is no block. 

But if we may decline the choice at time 0 (effectively by “taking both
choices”), that had better not block the /environment/ from progressing,
otherwise everything will stop. The problem is that the environment doesn't, in
general, provide us with all choices. 

What does it mean for the behaviour of the environment to be “known up to time
$\tau$”? Let $B$ be a behaviour and $E$ be the behaviour of the environment. I
guess it means:

1. For every $e \in E$ there is some $h \in B$ such that $h$ is a prefix of $e$;

2. For every $h \in B$ there is some $e \in E$ such that $h$ is a prefix of $e$;

3. There is an integer $\tau$ such that $|h| \geq \tau$ for every $h \in B$. 

How do we say, “we don't yet know what specific behavoiur the environment will
exhibit (let alone which history will be chosen) but we do know that it will be
such as to ensure that there is also at least one possible history.”

We need some notion (possibly the same as above) of “this behaviour has some
other behaviour as a prefix.”

The general idea is:
- The environment is specified as a behaviour, $E_t$;
- We compute the intersection of $E_t$ with the machine's behaviour, to get
  $O_t$ ($O$ for output).
- We compute, in particular, the longest common prefix of $O_t$, say $h_t$. 
- A new environment is specified, $E_{t+1}$, such that
\begin{equation*}
E_{t+1} \subset E_t.
\end{equation*}
- We compute $O_{t+1}$, and thus $h_{t+1}$. 
- We note that we can write $h_{t+1}$ as $h_{t+1} = h_t \then s$ for some $s$,
  and we “emit” $s$.

** What's left?

What's left is to specify the ways of writing down behaviours and the
computation on these of the previous steps. 

* Usable programs



* Todo

** Prefix-closure

What if the behaviours are prefix-closed? 

- Does the distributive law now hold? (No.)
- Should we redefine $\sync$ to be “intersect the prefix”? 
- Are the operators strict (and do they preserve prefix-closure)?

** Strictness

- Should we redefine behaviour to include $\e$ always? 
  No: some programs insist on a certain prefix.

** Non-determinism

- “Compile” behaviours for “parallel machines”. Then, when the result runs on
  only one machine, run it. 

* Footnotes

[fn:kleene] I've used the Kleene star without introducing it.

  

